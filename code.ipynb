{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mz0_QVkxCrX3"
   },
   "source": [
    "# **COVID-19 Cases Prediction (Regression)**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilzLcN2qKMde"
   },
   "source": [
    "# **Setup Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqnV0o0zB_qD"
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "geo_type = \"state\"\n",
    "exp_num = 1\n",
    "day_seq = [1,3,7,10,14]\n",
    "\n",
    "# model and target\n",
    "model_num = 3\n",
    "model_pr = 'origin'\n",
    "target_only = False\n",
    "\n",
    "# model parameters\n",
    "n_epochs = 5000\n",
    "batch_size = 16\n",
    "optimizer = 'Adam'\n",
    "lr = 0.0001\n",
    "weight_decay = 0.0005\n",
    "betas = (0.9, 0.999)\n",
    "early_stop = 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS_4-77xHk44"
   },
   "source": [
    "# **Import Some Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-onQd4JNA5H"
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtE3b6JEH7rw"
   },
   "source": [
    "# **Some Utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWMT3uf1NGQp"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
    "    plt.ylim(0.0, 5.)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.savefig(f'learning_curve_{geo_type}_day{day_num}_exp{exp_num}')\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_valid(dv_set, model, device, lim=35., preds=None, targets=None):\n",
    "    ''' Plot validation of your DNN '''\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        for x, y in dv_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim=0).numpy()\n",
    "        targets = torch.cat(targets, dim=0).numpy()\n",
    "\n",
    "    figure(figsize=(5, 5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
    "    plt.xlim(-0.2, lim)\n",
    "    plt.ylim(-0.2, lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth v.s. Validation')\n",
    "    plt.savefig(f'validation_{geo_type}_day{day_num}_exp{exp_num}')\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "    \n",
    "def plot_pred(tt_set, model, device, lim=35., preds=None, targets=None):\n",
    "    ''' Plot prediction of your DNN '''\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        for x, y in tt_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim=0).numpy()\n",
    "        targets = torch.cat(targets, dim=0).numpy()\n",
    "\n",
    "    figure(figsize=(5, 5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
    "    plt.xlim(-0.2, lim)\n",
    "    plt.ylim(-0.2, lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth v.s. Prediction')\n",
    "    plt.savefig(f'prediction_{geo_type}_day{day_num}_exp{exp_num}')\n",
    "    plt.close()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39U_XFX6KOoj"
   },
   "source": [
    "# **Preprocess**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQ-MdwpLL7Dt"
   },
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zlpIp9ANJRU"
   },
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 mode='train',\n",
    "                 target_only=False):\n",
    "        self.mode = mode\n",
    "\n",
    "        # Read data into numpy arrays\n",
    "        with open(path, 'r') as fp:\n",
    "            data = list(csv.reader(fp))\n",
    "            data = np.array(data[1:])[:, 1:].astype(float)\n",
    "        \n",
    "        if not target_only:\n",
    "            feats = list(range(day_num*18-1))\n",
    "        else:\n",
    "            # feats = list(range(day_num*4)) + list(range(day_num*17, day_num*18-1))\n",
    "            feats = list(range(day_num*17, day_num*18-1))\n",
    "            pass\n",
    "\n",
    "        if mode == 'test':\n",
    "            # Testing data\n",
    "            data = data[:, feats]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "            target = data[:, -1]\n",
    "            self.target = torch.FloatTensor(target)\n",
    "        else:\n",
    "            # Training data (train/dev sets)\n",
    "            target = data[:, -1]\n",
    "            data = data[:, feats]\n",
    "            \n",
    "            # Splitting training data into train & dev sets\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 != 1]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 == 1]\n",
    "            \n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "        self.dim = self.data.shape[1]\n",
    "\n",
    "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
    "              .format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing (no target)\n",
    "            # return self.data[index]\n",
    "            return self.data[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlhTlkE7MDo3"
   },
   "source": [
    "## **DataLoader**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlhLk5t6MBX3"
   },
   "outputs": [],
   "source": [
    "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size,\n",
    "        shuffle=(mode == 'train'), drop_last=False,\n",
    "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGuycwR0MeQB"
   },
   "source": [
    "# **Deep Neural Network**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49-uXYovOAI0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # model 1\n",
    "        if model_num == 1:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(input_dim, 1),\n",
    "            )\n",
    "        \n",
    "        # model 2\n",
    "        elif model_num == 2:\n",
    "            self.net = nn.Sequential(        \n",
    "                nn.Linear(input_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1),\n",
    "            )\n",
    "            \n",
    "        # model 3\n",
    "        elif model_num == 3:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(input_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1),\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            print(\"model selection error\")\n",
    "        \n",
    "\n",
    "        # Mean squared error loss\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        return self.criterion(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvFWVjZ5Nvga"
   },
   "source": [
    "# **Train/Dev/Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAM8QecJOyqn"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOqcmYzMO7jB"
   },
   "outputs": [],
   "source": [
    "def train(tr_set, dv_set, model, config, device):\n",
    "    ''' DNN training '''\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(model.parameters(), **config['optim_hparas'])\n",
    "\n",
    "    min_mse = 1000.0\n",
    "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
    "    early_stop_cnt = 0\n",
    "    final_epoch = 0\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        for x, y in tr_set:                     # iterate through the dataloader\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
    "\n",
    "        # After each epoch, test model on the validation (development) set.\n",
    "        dev_mse = dev(dv_set, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            # Save model if model improved\n",
    "            min_mse = dev_mse\n",
    "            print('Saving model (epoch = {:4d}, loss = {:.4f})'.format(epoch + 1, min_mse))\n",
    "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
    "            final_epoch = epoch + 1\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        loss_record['dev'].append(dev_mse)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            # Stop training if model stops improving for \"config['early_stop']\" epochs.\n",
    "            break\n",
    "\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_mse, loss_record, final_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hSd4Bn3O2PL"
   },
   "source": [
    "## **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrxrD3YsN3U2"
   },
   "outputs": [],
   "source": [
    "def dev(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    total_loss = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0pdrhQAO41L"
   },
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSBMRFlYN5tB"
   },
   "outputs": [],
   "source": [
    "def test(tt_set, model, device):\n",
    "\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    testing_loss = 0\n",
    "    for x, y in tt_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        testing_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    testing_loss = testing_loss / len(tt_set.dataset)            # compute averaged loss\n",
    "    \n",
    "    return testing_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvckkF5dvf0j"
   },
   "source": [
    "# **Setup Hyper-parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPXpdumwPjE7"
   },
   "outputs": [],
   "source": [
    "device = get_device()                    # Get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)     # The trained model will be saved to ./models/\n",
    "target_only = target_only                # Use selected features\n",
    "\n",
    "config = {\n",
    "    'n_epochs': n_epochs,                   # maximum number of epochs\n",
    "    'batch_size': batch_size,               # mini-batch size for dataloader\n",
    "    'optimizer': optimizer,                 # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                       # hyper-parameters for the optimizer\n",
    "        'lr': lr,                           # learning rate\n",
    "        'weight_decay': weight_decay,       # weight decay: to avoid overfitting\n",
    "        'betas': betas                      # betas: to smooth the training curve\n",
    "        # 'momentum': 0.9                     # momentum for SGD\n",
    "    },\n",
    "    'early_stop': early_stop,               # early stopping epochs (the number epochs since model's last improvement)\n",
    "    'save_path': 'models/model.pth'         # save model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j1eOV3TOH-j"
   },
   "source": [
    "# **Training and Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNrYBMmePLKm",
    "outputId": "2de3865e-c91d-46ac-9b51-9a18e41311bf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------Training day3-------------------------------\n",
      "Finished reading the train set of COVID19 Dataset (1957 samples found, each dim = 2)\n",
      "Finished reading the dev set of COVID19 Dataset (218 samples found, each dim = 2)\n",
      "Finished reading the test set of COVID19 Dataset (300 samples found, each dim = 2)\n",
      "\n",
      "\n",
      "Saving model (epoch =    1, loss = 17.5712)\n",
      "Saving model (epoch =    2, loss = 1.1982)\n",
      "Saving model (epoch =    3, loss = 1.1748)\n",
      "Saving model (epoch =    4, loss = 1.1712)\n",
      "Saving model (epoch =    5, loss = 1.1230)\n",
      "Saving model (epoch =    6, loss = 1.0928)\n",
      "Saving model (epoch =    7, loss = 1.0374)\n",
      "Saving model (epoch =    8, loss = 0.9609)\n",
      "Saving model (epoch =    9, loss = 0.9082)\n",
      "Saving model (epoch =   10, loss = 0.8677)\n",
      "Saving model (epoch =   12, loss = 0.8382)\n",
      "Saving model (epoch =   15, loss = 0.8194)\n",
      "Saving model (epoch =   16, loss = 0.8165)\n",
      "Saving model (epoch =   20, loss = 0.8146)\n",
      "Saving model (epoch =   23, loss = 0.8136)\n",
      "Saving model (epoch =   28, loss = 0.8125)\n",
      "Finished training after 379 epochs\n",
      "\n",
      "Result:\n",
      "final_epoch_day3 = 28\n",
      "train_final_loss_day3 = 0.8125358202041836\n",
      "testing_loss_day3 = 0.5904426960150401\n",
      "\n",
      "\n",
      "-------------------------------Training day7-------------------------------\n",
      "Finished reading the train set of COVID19 Dataset (1765 samples found, each dim = 6)\n",
      "Finished reading the dev set of COVID19 Dataset (197 samples found, each dim = 6)\n",
      "Finished reading the test set of COVID19 Dataset (300 samples found, each dim = 6)\n",
      "\n",
      "\n",
      "Saving model (epoch =    1, loss = 3.0010)\n",
      "Saving model (epoch =    2, loss = 2.3914)\n",
      "Saving model (epoch =    3, loss = 1.5333)\n",
      "Saving model (epoch =    4, loss = 1.3872)\n",
      "Saving model (epoch =    5, loss = 1.3590)\n",
      "Saving model (epoch =    6, loss = 1.3309)\n",
      "Saving model (epoch =    9, loss = 1.2382)\n",
      "Saving model (epoch =   10, loss = 1.2176)\n",
      "Saving model (epoch =   12, loss = 1.1786)\n",
      "Saving model (epoch =   14, loss = 1.1604)\n",
      "Saving model (epoch =   15, loss = 1.1533)\n",
      "Saving model (epoch =   18, loss = 1.1456)\n",
      "Saving model (epoch =   21, loss = 1.1423)\n",
      "Saving model (epoch =   24, loss = 1.1359)\n",
      "Saving model (epoch =   27, loss = 1.1346)\n",
      "Saving model (epoch =   43, loss = 1.1303)\n",
      "Saving model (epoch =   49, loss = 1.1284)\n",
      "Saving model (epoch =   54, loss = 1.1256)\n",
      "Finished training after 405 epochs\n",
      "\n",
      "Result:\n",
      "final_epoch_day7 = 54\n",
      "train_final_loss_day7 = 1.1255970594241533\n",
      "testing_loss_day7 = 0.7391420690218607\n",
      "\n",
      "\n",
      "-------------------------------Training day10-------------------------------\n",
      "Finished reading the train set of COVID19 Dataset (1625 samples found, each dim = 9)\n",
      "Finished reading the dev set of COVID19 Dataset (181 samples found, each dim = 9)\n",
      "Finished reading the test set of COVID19 Dataset (300 samples found, each dim = 9)\n",
      "\n",
      "\n",
      "Saving model (epoch =    1, loss = 13.5185)\n",
      "Saving model (epoch =    2, loss = 4.1471)\n",
      "Saving model (epoch =    3, loss = 2.9190)\n",
      "Saving model (epoch =    4, loss = 1.8677)\n",
      "Saving model (epoch =    5, loss = 1.4734)\n",
      "Saving model (epoch =    6, loss = 1.3162)\n",
      "Saving model (epoch =    7, loss = 1.3019)\n",
      "Saving model (epoch =    8, loss = 1.2752)\n",
      "Saving model (epoch =    9, loss = 1.1553)\n",
      "Saving model (epoch =   10, loss = 1.1210)\n",
      "Saving model (epoch =   11, loss = 1.0525)\n",
      "Saving model (epoch =   14, loss = 1.0277)\n",
      "Saving model (epoch =   16, loss = 0.9977)\n",
      "Saving model (epoch =   18, loss = 0.9882)\n",
      "Saving model (epoch =   19, loss = 0.9741)\n",
      "Saving model (epoch =   20, loss = 0.9697)\n",
      "Saving model (epoch =   23, loss = 0.9564)\n",
      "Saving model (epoch =   25, loss = 0.9436)\n",
      "Saving model (epoch =   29, loss = 0.9335)\n",
      "Saving model (epoch =   31, loss = 0.9237)\n",
      "Saving model (epoch =   32, loss = 0.9205)\n",
      "Saving model (epoch =   36, loss = 0.9148)\n",
      "Saving model (epoch =   37, loss = 0.8983)\n",
      "Saving model (epoch =   43, loss = 0.8822)\n",
      "Saving model (epoch =   46, loss = 0.8800)\n",
      "Saving model (epoch =   47, loss = 0.8732)\n",
      "Saving model (epoch =   49, loss = 0.8715)\n",
      "Saving model (epoch =   52, loss = 0.8449)\n",
      "Saving model (epoch =   58, loss = 0.8377)\n",
      "Saving model (epoch =   61, loss = 0.8310)\n",
      "Saving model (epoch =   65, loss = 0.8208)\n",
      "Saving model (epoch =   71, loss = 0.8197)\n",
      "Saving model (epoch =   74, loss = 0.8133)\n",
      "Saving model (epoch =   76, loss = 0.8030)\n",
      "Saving model (epoch =   82, loss = 0.8020)\n",
      "Saving model (epoch =   87, loss = 0.7902)\n",
      "Saving model (epoch =   89, loss = 0.7871)\n",
      "Saving model (epoch =   90, loss = 0.7830)\n",
      "Saving model (epoch =   97, loss = 0.7784)\n",
      "Saving model (epoch =   99, loss = 0.7779)\n",
      "Saving model (epoch =  105, loss = 0.7729)\n",
      "Saving model (epoch =  108, loss = 0.7684)\n",
      "Saving model (epoch =  117, loss = 0.7582)\n",
      "Saving model (epoch =  125, loss = 0.7533)\n",
      "Saving model (epoch =  136, loss = 0.7522)\n",
      "Saving model (epoch =  150, loss = 0.7414)\n",
      "Saving model (epoch =  159, loss = 0.7394)\n",
      "Saving model (epoch =  163, loss = 0.7321)\n",
      "Saving model (epoch =  193, loss = 0.7312)\n",
      "Saving model (epoch =  195, loss = 0.7275)\n",
      "Saving model (epoch =  201, loss = 0.7221)\n",
      "Saving model (epoch =  202, loss = 0.7204)\n",
      "Saving model (epoch =  232, loss = 0.7189)\n",
      "Saving model (epoch =  237, loss = 0.7180)\n",
      "Saving model (epoch =  238, loss = 0.7146)\n",
      "Saving model (epoch =  244, loss = 0.7119)\n",
      "Saving model (epoch =  276, loss = 0.7086)\n",
      "Saving model (epoch =  291, loss = 0.7075)\n",
      "Saving model (epoch =  300, loss = 0.6907)\n",
      "Saving model (epoch =  361, loss = 0.6904)\n",
      "Saving model (epoch =  396, loss = 0.6878)\n",
      "Saving model (epoch =  442, loss = 0.6872)\n",
      "Saving model (epoch =  449, loss = 0.6848)\n",
      "Saving model (epoch =  458, loss = 0.6716)\n",
      "Saving model (epoch =  561, loss = 0.6675)\n",
      "Saving model (epoch =  606, loss = 0.6644)\n",
      "Saving model (epoch =  614, loss = 0.6629)\n",
      "Saving model (epoch =  725, loss = 0.6598)\n",
      "Saving model (epoch =  835, loss = 0.6576)\n",
      "Finished training after 1186 epochs\n",
      "\n",
      "Result:\n",
      "final_epoch_day10 = 835\n",
      "train_final_loss_day10 = 0.6576211340519604\n",
      "testing_loss_day10 = 0.39676475087801616\n",
      "\n",
      "\n",
      "-------------------------------Training day14-------------------------------\n",
      "Finished reading the train set of COVID19 Dataset (1448 samples found, each dim = 13)\n",
      "Finished reading the dev set of COVID19 Dataset (161 samples found, each dim = 13)\n",
      "Finished reading the test set of COVID19 Dataset (300 samples found, each dim = 13)\n",
      "\n",
      "\n",
      "Saving model (epoch =    1, loss = 6.1873)\n",
      "Saving model (epoch =    2, loss = 5.4078)\n",
      "Saving model (epoch =    3, loss = 4.6878)\n",
      "Saving model (epoch =    4, loss = 3.9524)\n",
      "Saving model (epoch =    5, loss = 3.1056)\n",
      "Saving model (epoch =    6, loss = 2.6053)\n",
      "Saving model (epoch =    7, loss = 2.2692)\n",
      "Saving model (epoch =    8, loss = 1.8939)\n",
      "Saving model (epoch =    9, loss = 1.7046)\n",
      "Saving model (epoch =   10, loss = 1.5115)\n",
      "Saving model (epoch =   11, loss = 1.3856)\n",
      "Saving model (epoch =   13, loss = 1.2468)\n",
      "Saving model (epoch =   15, loss = 1.1562)\n",
      "Saving model (epoch =   16, loss = 1.1216)\n",
      "Saving model (epoch =   17, loss = 1.0969)\n",
      "Saving model (epoch =   20, loss = 0.9840)\n",
      "Saving model (epoch =   21, loss = 0.9577)\n",
      "Saving model (epoch =   23, loss = 0.9461)\n",
      "Saving model (epoch =   25, loss = 0.9160)\n",
      "Saving model (epoch =   26, loss = 0.9156)\n",
      "Saving model (epoch =   27, loss = 0.9034)\n",
      "Saving model (epoch =   31, loss = 0.8885)\n",
      "Saving model (epoch =   32, loss = 0.8679)\n",
      "Saving model (epoch =   34, loss = 0.8597)\n",
      "Saving model (epoch =   36, loss = 0.8469)\n",
      "Saving model (epoch =   39, loss = 0.8361)\n",
      "Saving model (epoch =   41, loss = 0.8287)\n",
      "Saving model (epoch =   43, loss = 0.8207)\n",
      "Saving model (epoch =   46, loss = 0.8095)\n",
      "Saving model (epoch =   47, loss = 0.8086)\n",
      "Saving model (epoch =   55, loss = 0.7869)\n",
      "Saving model (epoch =   56, loss = 0.7855)\n",
      "Saving model (epoch =   58, loss = 0.7841)\n",
      "Saving model (epoch =   60, loss = 0.7749)\n",
      "Saving model (epoch =   62, loss = 0.7735)\n",
      "Saving model (epoch =   66, loss = 0.7610)\n",
      "Saving model (epoch =   73, loss = 0.7573)\n",
      "Saving model (epoch =   74, loss = 0.7557)\n",
      "Saving model (epoch =   83, loss = 0.7402)\n",
      "Saving model (epoch =   93, loss = 0.7301)\n",
      "Saving model (epoch =  100, loss = 0.7263)\n",
      "Saving model (epoch =  115, loss = 0.7250)\n",
      "Saving model (epoch =  116, loss = 0.7194)\n",
      "Saving model (epoch =  118, loss = 0.7180)\n",
      "Saving model (epoch =  124, loss = 0.7175)\n",
      "Saving model (epoch =  129, loss = 0.7154)\n",
      "Saving model (epoch =  135, loss = 0.7118)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =  143, loss = 0.7113)\n",
      "Saving model (epoch =  177, loss = 0.7072)\n",
      "Saving model (epoch =  195, loss = 0.7035)\n",
      "Saving model (epoch =  197, loss = 0.7000)\n",
      "Saving model (epoch =  340, loss = 0.6999)\n",
      "Saving model (epoch =  365, loss = 0.6991)\n",
      "Saving model (epoch =  367, loss = 0.6990)\n",
      "Saving model (epoch =  372, loss = 0.6971)\n",
      "Saving model (epoch =  380, loss = 0.6942)\n",
      "Saving model (epoch =  388, loss = 0.6900)\n",
      "Saving model (epoch =  444, loss = 0.6884)\n",
      "Saving model (epoch =  526, loss = 0.6834)\n",
      "Finished training after 877 epochs\n",
      "\n",
      "Result:\n",
      "final_epoch_day14 = 526\n",
      "train_final_loss_day14 = 0.6833971509281893\n",
      "testing_loss_day14 = 0.36675647099812825\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_epochs = []\n",
    "train_final_loss_total = []\n",
    "testing_loss_total = []\n",
    "\n",
    "for i in range(len(day_seq)):\n",
    "    \n",
    "    day_num = day_seq[i]\n",
    "\n",
    "    print(f\"-------------------------------Training day{day_num}-------------------------------\")\n",
    "\n",
    "    '''Set random seed'''\n",
    "    myseed = 42069  # set a random seed for reproducibility\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(myseed)\n",
    "    torch.manual_seed(myseed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(myseed)\n",
    "\n",
    "    '''Set data path'''\n",
    "    tr_path = f'covid.train.{geo_type}.{day_num}day.csv'  # path to training data\n",
    "    tt_path = f'covid.test.{geo_type}.{day_num}day.csv'   # path to testing data\n",
    "\n",
    "    '''Load data and model'''\n",
    "    tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
    "    dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
    "    tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)\n",
    "\n",
    "    model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device\n",
    "\n",
    "    '''Start Training'''\n",
    "    model_loss, model_loss_record, final_epoch = train(tr_set, dv_set, model, config, device)\n",
    "\n",
    "    '''Save plots'''\n",
    "    plot_learning_curve(model_loss_record, title='deep model')\n",
    "\n",
    "    del model\n",
    "    model = NeuralNet(tr_set.dataset.dim).to(device)\n",
    "    ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
    "    model.load_state_dict(ckpt)\n",
    "    plot_valid(dv_set, model, device)  # Show prediction on the validation set\n",
    "\n",
    "    '''Testing'''\n",
    "    testing_loss = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
    "    plot_pred(tt_set, model, device)  # Show prediction on the testing set\n",
    "\n",
    "    '''Save results'''\n",
    "    final_epochs.append(final_epoch)\n",
    "    train_final_loss_total.append(model_loss)\n",
    "    testing_loss_total.append(testing_loss)\n",
    "\n",
    "    '''Print results'''\n",
    "    print('\\nResult:')\n",
    "    print(f'final_epoch_day{day_num} = {final_epoch}')\n",
    "    print(f'train_final_loss_day{day_num} = {model_loss}')\n",
    "    print(f'testing_loss_day{day_num} = {testing_loss}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xjPMdmAImLd"
   },
   "source": [
    "# **Get output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPV5Vv-bB_qL"
   },
   "outputs": [],
   "source": [
    "'''Build dataframe'''\n",
    "final_epoch_sr = pd.Series(final_epochs)\n",
    "train_final_loss_sr = pd.Series(train_final_loss_total)\n",
    "testing_loss_sr = pd.Series(testing_loss_total)\n",
    "\n",
    "result = pd.DataFrame({'exp_num': exp_num,\n",
    "                       'day_num': day_seq,\n",
    "                       'target_only': target_only,\n",
    "                       'model': model_num,\n",
    "                       'model_pr.': model_pr,\n",
    "                       'n_epochs': n_epochs,\n",
    "                       'batch_size': batch_size,\n",
    "                       'optimizer': optimizer,\n",
    "                       'lr': lr,\n",
    "                       'weight_decay': weight_decay,\n",
    "                       'betas': str(betas),\n",
    "                       'early_stop': early_stop,\n",
    "                       'final_epoch': final_epoch_sr, \n",
    "                       'train_final_loss': train_final_loss_sr, \n",
    "                       'testing_loss': testing_loss_sr})\n",
    "\n",
    "result.to_csv(f'data_{geo_type}_exp{exp_num}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhLSFVjeB_qL",
    "outputId": "e0ff3063-9901-46d4-8c8b-7a26d9031e35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_num</th>\n",
       "      <th>day_num</th>\n",
       "      <th>target_only</th>\n",
       "      <th>model</th>\n",
       "      <th>model_pr.</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>betas</th>\n",
       "      <th>early_stop</th>\n",
       "      <th>final_epoch</th>\n",
       "      <th>train_final_loss</th>\n",
       "      <th>testing_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>tested_positive_only</td>\n",
       "      <td>5000</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>(0.9, 0.999)</td>\n",
       "      <td>350</td>\n",
       "      <td>28</td>\n",
       "      <td>0.812536</td>\n",
       "      <td>0.590443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>tested_positive_only</td>\n",
       "      <td>5000</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>(0.9, 0.999)</td>\n",
       "      <td>350</td>\n",
       "      <td>54</td>\n",
       "      <td>1.125597</td>\n",
       "      <td>0.739142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>tested_positive_only</td>\n",
       "      <td>5000</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>(0.9, 0.999)</td>\n",
       "      <td>350</td>\n",
       "      <td>835</td>\n",
       "      <td>0.657621</td>\n",
       "      <td>0.396765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>tested_positive_only</td>\n",
       "      <td>5000</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>(0.9, 0.999)</td>\n",
       "      <td>350</td>\n",
       "      <td>526</td>\n",
       "      <td>0.683397</td>\n",
       "      <td>0.366756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exp_num  day_num  target_only  model             model_pr.  n_epochs  \\\n",
       "0        9        3         True      3  tested_positive_only      5000   \n",
       "1        9        7         True      3  tested_positive_only      5000   \n",
       "2        9       10         True      3  tested_positive_only      5000   \n",
       "3        9       14         True      3  tested_positive_only      5000   \n",
       "\n",
       "   batch_size optimizer      lr  weight_decay         betas  early_stop  \\\n",
       "0          16      Adam  0.0001        0.0005  (0.9, 0.999)         350   \n",
       "1          16      Adam  0.0001        0.0005  (0.9, 0.999)         350   \n",
       "2          16      Adam  0.0001        0.0005  (0.9, 0.999)         350   \n",
       "3          16      Adam  0.0001        0.0005  (0.9, 0.999)         350   \n",
       "\n",
       "   final_epoch  train_final_loss  testing_loss  \n",
       "0           28          0.812536      0.590443  \n",
       "1           54          1.125597      0.739142  \n",
       "2          835          0.657621      0.396765  \n",
       "3          526          0.683397      0.366756  "
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Print dataframe'''\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
